# ICDM2022：大规模电商图上的风险商品检测 技术报告

团队名：躺平不如起立，成员：杨思超，日期：2022-09-04

## 1. 比赛目标及挑战

比赛目标是在大规模含噪声的异构图上，设计算法模型对分布不均的黑白样本进行检测。主要的挑战是如何解决噪声大，分布不均，模型泛化和大规模训练问题。

## 2. 技术总结

这次选取的技术方案整体包含了以下几个关键模块：

* NARS
* semi-supervised learning: mutual-mean teaching, fixmatch
* unbalanced weights & hard example learning

### 2.1 NARS

[Neighbor Averaging over Relation Subgraphs](http://arxiv.org/abs/2011.09679), 是在[SIGN](https://arxiv.org/abs/2004.11198)基础上在heterogeneous graph上的改进，而SIGN是[simplify gcn](https://proceedings.mlr.press/v97/wu19e.html)上的发展。simplify gcn中核心的概念是之前的大规模图上sample的方法（[sage](https://arxiv.org/pdf/1706.02216.pdf)，[saint](https://arxiv.org/pdf/1907.04931.pdf)）由于限制采样邻居数且只在subset上采样会引入bias，且sampling上做的多层non-linear transformation实际上没有多大的作用，所以直接去掉了message passing里的NL transform。SIGN是把inception的概念引入了图学习，把不同hop上聚合的local info拼接起来喂入分类器。NARS把这个技术利用[metapath](https://dl.acm.org/doi/10.1145/3097983.3098036)的概念进一步拓展到了异构图上，sample不同的metapath作为subsets学习。

在这次竞赛的实验中，nars表现优于[rgcn](http://arxiv.org/abs/1703.06103)和[hgt](https://arxiv.org/abs/2003.01332)，分析原因是因为这次的图噪声很大与其在包含所有类型节点全图上采样不如在只包含部分类型节点的metapath上采样更能够聚合到有价值的信息，采样深度也可以做得更深。另外NARS可以把特征生成和标签分类两部分分开，两部分单独调优，整体学习更高效。

### 2.2 Semi-supervised learning

比赛有标签的数据只有全量数据0.6%，为了更好利用这些没有标签的数据，我的方案里借鉴了两个流行的自监督学习里的方法：[Fixmatch](https://arxiv.org/ftp/arxiv/papers/2001/2001.07685.pdf)和[mutual-mean teaching](http://arxiv.org/abs/2001.01526)。原始第一个方法是处理图像相关的任务，利用关于图像数据的增强来做consistency regularization。对于图任务，我们随机的dropout输入的节点数据，然后要求结果和没有regularized的结果距离接近。第二个方法提到为了降低自监督或者伪标签学习常见的bias confirmation问题，他们设计了两个网络相互在线和离线学习。两个网络的参数设置相互独立，看到的数据也可以相互独立这样能有效降低不断过于强化自信的错误预测的风险。所以我这里利用cv里当前模型以外的其他模型来做除了train|dev set以外的unlabelled data的pseudo labelling，并利用参数mu来控制引入无标签样本的比例。

除了以上的技术，还有常见的label confidence threshold annealing和[label smoothing](http://arxiv.org/abs/1512.00567)技术。

在实验里，我发现结合regularization，dev set上的精度能够小幅提升。

### 2.3 Unbalanced weights & hard example learning

为了接近正负样本分布不均衡的问题，且基于公开信息测试集正例更低，这里使用了[focal loss](http://arxiv.org/abs/1708.02002)和负权重略高于正权重的策略。这两项技术也帮助模型精度的线上成绩小幅提升。

## 3. 消融实验

因为比赛的时候没有很好保留模型参数，现在只能从valuation set上来做消融实验的展示。第一二赛季的结果可以运行项目配置文件`config/dgl_session[].yml`来复现。

第一组实验是从采样方法和模型结构上的对比。[rgcn](http://arxiv.org/abs/1703.06103)和[hgt](http://arxiv.org/abs/2003.01332)都是经典的异构图模型。signv1是原始的sign模型，v2里把最后的output层做替换成了加skip connection的非线性层，v3是把原本inception的压缩层做了平滑处理降低信息压缩太大风险，v4尝试使用self-attention来处理不同hops的feature相互之间的关系，v5把inception的拼接压缩换成了加权加和。GAMLP模型则是之前在[ogb](https://ogb.stanford.edu/docs/leader_nodeprop/) node prediction任务上霸榜的模型。

可以看到，首先sign的采样方法整体性能优于其余两种采样方法。然后就是原始的sign的表现优于所有模型，无论是在val_ap的维度还是在train-val difference的维度上看。

|               | train_ap | val_ap   | param   |
| ------------- | -------- | -------- | ------- |
| rgcn          | 9467     | 9350     | -       |
| hgt           | 9476     | 9321     | -       |
| SIGNV1        | ==9608== | ==9523== | 1511245 |
| SIGNV2        | 9875     | 9498     | 1510863 |
| SIGNV3        | 9795     | 9507     | 5002289 |
| SIGNV4        | 9407     | 9379     | 5150513 |
| SIGNV5        | 9868     | 9504     | 1215961 |
| NARS_R_GAMLP  | 9357     | 9369     | 1672337 |
| NARS_JK_GAMLP | 9333     | 9308     | 928720  |

第二组实验是对比的consistency regularization的作用，可以看到没有加regularization的ap最低，加了之后精度有小幅上升。[scr](http://arxiv.org/abs/2112.04319)就是用的time-averaged model来输出正则化用的目标分布。而dcr就是方案里提出的把数据大幅dropout后模型输出的分布以及正常数据输入模型后的分布来做正则化：
$$
\bar{y}=M_{avg}(x) \quad or \quad M(do(x))\\
Loss =Dist.(\bar{y}, \hat{y})\\
$$

|         | train_ap | val_ap   |
| ------- | -------- | -------- |
| w/o cr  | 9757     | 9540     |
| scr     | 9807     | 9545     |
| dcr     | 9792     | 9548     |
| scr+dcr | ==9806== | ==9555== |

第三组实验是针对正负不平衡问题的损失函数，实验发现少量的focal loss可以提升ap值。

|         | train_ap | val_ap   |
| ------- | -------- | -------- |
| cross_e | 9842     | 9538     |
| focal_1 | ==9864== | ==9566== |
| focal_2 | 9806     | 9555     |
| focal_3 | 9719     | 9511     |

第三组实验是采用不同hop深度带来的精度变化，可以看到hop3以上的精度提升就极为有限了，说明在没有学到很好区分噪声的方法的前提下，更大的hop深度并不会带来明显的精度提升。在赛题描述里看到以item节点为中心1~3个hop的距离基本可以覆盖周边不同类型的节点。所以说明给定当前模型，走出了这个范围走入别的item的范围里收集信息并不会提高精度。

|       | train_ap | val_ap   |
| ----- | -------- | -------- |
| hop_8 | ==9845== | ==9566== |
| hop_6 | 9733     | 9561     |
| hop_3 | 9834     | 9542     |
| hop_1 | 9691     | 9489     |
| hop_0 | 9241     | 8929     |

## 4. 后续方向

从上述分析可知，其实这次的方案并没有很好的收集到更深距离的节点信息，同时session2的模型线上得分明显低于val set的得分，说明当前模型的泛化性存在不足这也是应该解决的问题，期待看到top选手的解决方案。我猜想通过针对节点或图的预训练来提升表达能力，训练中[主动识别噪声提高鲁棒性](https://arxiv.org/pdf/2201.00232.pdf)，或许是一种解决方法。